{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import os\n",
    "import sklearn.feature_extraction.text as text\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in the woods...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now in the building across the street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "5   8     NaN      NaN   \n",
       "6  10     NaN      NaN   \n",
       "7  13     NaN      NaN   \n",
       "8  14     NaN      NaN   \n",
       "9  15     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "5  #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAf...   \n",
       "6      #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas   \n",
       "7                                          I'm on top of the hill and I can see a fire in the woods...   \n",
       "8                      There's an emergency evacuation happening now in the building across the street   \n",
       "9                                                 I'm afraid that the tornado is coming to our area...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',100)\n",
    "# Load training set \n",
    "train = pd.read_csv('text-data/train.csv')\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring what the unique keywords and locations are \n",
    "non_null_kw = train.keyword.notnull()\n",
    "non_null_loc = train.location.notnull()\n",
    "train['keyword'][non_null_kw].unique()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Birmingham', 'Est. September 2012 - Bristol', 'AFRICA',\n",
       "       'Philadelphia, PA', 'London, UK', 'Pretoria', 'World Wide!!',\n",
       "       'Paranaque City', 'Live On Webcam', 'milky way',\n",
       "       'GREENSBORO,NORTH CAROLINA', 'England.',\n",
       "       'Sheffield Township, Ohio', 'India', 'Barbados', 'Anaheim',\n",
       "       'Abuja', 'USA', 'South Africa', 'Sao Paulo, Brazil',\n",
       "       'hollywoodland ', 'Edmonton, Alberta - Treaty 6',\n",
       "       'Inang Pamantasan', 'Twitter Lockout in progress', 'Concord, CA',\n",
       "       'Calgary, AB', 'San Francisco', 'CLVLND', 'Nashville, TN',\n",
       "       'Santa Clara, CA'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['location'][non_null_loc].unique()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = train[['text','target']]\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import punkt # no punctuations \n",
    "from nltk import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "# create a data cleaning function that tokenizes, \n",
    "# removes english stopwords and punctuations and returns tokenized text in lowercase \n",
    "\n",
    "eng_stop = stopwords.words('english') # english stopwords\n",
    "re_pat = '^a-zA-Z\\s\\W+' # find all symbols and whitespaces \n",
    "\n",
    "def clean_text(text,pattern):\n",
    "    '''Removes punctuations and stopwords and returns lowercase tokenized text for input text and pattern'''\n",
    "    text_nospchar = re.sub(pattern,'',text,re.I | re.A) # match regex pattern and replace with empty string\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text_lower_nospc = text_nopunct.lower().strip() # convert text to lower case and strip white space if any\n",
    "    token_text = word_tokenize(text_lower_nospc) # convert to tokens \n",
    "    no_stop_docs = ' '.join([word for word in token_text if word not in eng_stop]) # list of tokenized words with no stopwords\n",
    "    \n",
    "    return no_stop_docs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-6ffdf0786a92>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus_df['cleaned_text'] = cleaner(corpus_df['text'],re_pat)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orders california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAf...</td>\n",
       "      <td>1</td>\n",
       "      <td>rockyfire update california hwy 20 closed directions due lake county fire cafire wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</td>\n",
       "      <td>1</td>\n",
       "      <td>flood disaster heavy rain causes flash flooding streets manitou colorado springs areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in the woods...</td>\n",
       "      <td>1</td>\n",
       "      <td>im top hill see fire woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now in the building across the street</td>\n",
       "      <td>1</td>\n",
       "      <td>theres emergency evacuation happening building across street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our area...</td>\n",
       "      <td>1</td>\n",
       "      <td>im afraid tornado coming area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "5  #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAf...   \n",
       "6      #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas   \n",
       "7                                          I'm on top of the hill and I can see a fire in the woods...   \n",
       "8                      There's an emergency evacuation happening now in the building across the street   \n",
       "9                                                 I'm afraid that the tornado is coming to our area...   \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "5       1   \n",
       "6       1   \n",
       "7       1   \n",
       "8       1   \n",
       "9       1   \n",
       "\n",
       "                                                                                 cleaned_text  \n",
       "0                                                deeds reason earthquake may allah forgive us  \n",
       "1                                                       forest fire near la ronge sask canada  \n",
       "2    residents asked shelter place notified officers evacuation shelter place orders expected  \n",
       "3                                 13000 people receive wildfires evacuation orders california  \n",
       "4                                     got sent photo ruby alaska smoke wildfires pours school  \n",
       "5  rockyfire update california hwy 20 closed directions due lake county fire cafire wildfires  \n",
       "6      flood disaster heavy rain causes flash flooding streets manitou colorado springs areas  \n",
       "7                                                                  im top hill see fire woods  \n",
       "8                                theres emergency evacuation happening building across street  \n",
       "9                                                               im afraid tornado coming area  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = np.vectorize(clean_text)\n",
    "corpus_df['cleaned_text'] = cleaner(corpus_df['text'],re_pat)\n",
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned text is now devoid of any special characters or stopwords, however its still not ready to be vectorized. The first action required is to tokenize the words, ie, converting the sentence into a list of words, and then, there can be many words that have a similar meaning such search, searching, searched, etc. I will be using a lemmatizer (WordNetLemmatizer) to correlate words with similar meaning and keeps the root words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_lemmatize(text):\n",
    "    '''Input is a string sentence, returns list of lemmatized tokens'''\n",
    "    \n",
    "    wn = nltk.WordNetLemmatizer() # Instantiating wordnet lemmatizer \n",
    "    tokens = re.split('\\W+',text) # split words on white space\n",
    "    text_lemmatized = [ wn.lemmatize(word) for word in tokens ] # lemmatize tokens and store as list\n",
    "    return text_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-e621ad8f330e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus_df['text_lemmatized'] = corpus_df['cleaned_text'].apply(lambda x: tokenize_lemmatize(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "      <td>[resident, asked, shelter, place, notified, officer, evacuation, shelter, place, order, expected]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orders california</td>\n",
       "      <td>[13000, people, receive, wildfire, evacuation, order, california]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfire, pours, school]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                               cleaned_text  \\\n",
       "0                                              deeds reason earthquake may allah forgive us   \n",
       "1                                                     forest fire near la ronge sask canada   \n",
       "2  residents asked shelter place notified officers evacuation shelter place orders expected   \n",
       "3                               13000 people receive wildfires evacuation orders california   \n",
       "4                                   got sent photo ruby alaska smoke wildfires pours school   \n",
       "\n",
       "                                                                                     text_lemmatized  \n",
       "0                                                 [deed, reason, earthquake, may, allah, forgive, u]  \n",
       "1                                                      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [resident, asked, shelter, place, notified, officer, evacuation, shelter, place, order, expected]  \n",
       "3                                  [13000, people, receive, wildfire, evacuation, order, california]  \n",
       "4                                   [got, sent, photo, ruby, alaska, smoke, wildfire, pours, school]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['text_lemmatized'] = corpus_df['cleaned_text'].apply(lambda x: tokenize_lemmatize(x))\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer\n",
    "CountVec = text.CountVectorizer(analyzer='word')\n",
    "# convert text to matrix of token counts\n",
    "count_matrix = CountVec.fit_transform(corpus_df['cleaned_text'])\n",
    "count_matrix = count_matrix.toarray()\n",
    "# convert count matrix to dataframe\n",
    "count_matrix_df = pd.DataFrame(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0011</th>\n",
       "      <th>001116</th>\n",
       "      <th>0025</th>\n",
       "      <th>005225</th>\n",
       "      <th>010156</th>\n",
       "      <th>010217</th>\n",
       "      <th>0104</th>\n",
       "      <th>010401</th>\n",
       "      <th>0106</th>\n",
       "      <th>0111</th>\n",
       "      <th>...</th>\n",
       "      <th>ûò800000</th>\n",
       "      <th>ûòthe</th>\n",
       "      <th>ûòåêcnbc</th>\n",
       "      <th>ûó</th>\n",
       "      <th>ûóbbc</th>\n",
       "      <th>ûóher</th>\n",
       "      <th>ûókody</th>\n",
       "      <th>ûónegligence</th>\n",
       "      <th>ûótech</th>\n",
       "      <th>ûówe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0011  001116  0025  005225  010156  010217  0104  010401  0106  0111  ...  \\\n",
       "0     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "1     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "2     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "3     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "4     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "5     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "6     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "7     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "8     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "9     0       0     0       0       0       0     0       0     0     0  ...   \n",
       "\n",
       "   ûò800000  ûòthe  ûòåêcnbc  ûó  ûóbbc  ûóher  ûókody  ûónegligence  ûótech  \\\n",
       "0         0      0         0   0      0      0       0             0       0   \n",
       "1         0      0         0   0      0      0       0             0       0   \n",
       "2         0      0         0   0      0      0       0             0       0   \n",
       "3         0      0         0   0      0      0       0             0       0   \n",
       "4         0      0         0   0      0      0       0             0       0   \n",
       "5         0      0         0   0      0      0       0             0       0   \n",
       "6         0      0         0   0      0      0       0             0       0   \n",
       "7         0      0         0   0      0      0       0             0       0   \n",
       "8         0      0         0   0      0      0       0             0       0   \n",
       "9         0      0         0   0      0      0       0             0       0   \n",
       "\n",
       "   ûówe  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "5     0  \n",
       "6     0  \n",
       "7     0  \n",
       "8     0  \n",
       "9     0  \n",
       "\n",
       "[10 rows x 22308 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract headings for count matrix\n",
    "features = CountVec.get_feature_names()\n",
    "count_matrix_df.columns = features\n",
    "count_matrix_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
